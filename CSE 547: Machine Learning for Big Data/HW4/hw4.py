# -*- coding: utf-8 -*-
"""HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fHm3wQnT7_nXEzAV8GkLGN35jJ50iUrS

# CSE547 - HW4

## Setup

Let's setup Spark on your Colab environment.  Run the cell below!
"""

!pip install pyspark
!pip install -U -q PyDrive
!apt install openjdk-8-jdk-headless -qq
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

from google.colab import drive
drive.mount('/content/drive')

import pyspark
from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark import SparkContext, SparkConf
from pyspark.sql import functions as F
from pyspark.rdd import RDD
import numpy as np
import pandas as pd

#sc.stop()

conf = SparkConf().set("spark.ui.port", "4050")
sc = SparkContext(conf=conf)
spark = SparkSession.builder \
.appName('app_name') \
.master('local[*]') \
.config('spark.sql.execution.arrow.pyspark.enabled', True) \
.config("spark.executor.memory", "70g")\
.config('spark.sql.session.timeZone', 'UTC') \
.config('spark.driver.memory','50g') \
.config("spark.memory.offHeap.size","16g")   \
.config('spark.ui.showConsoleProgress', True) \
.config('spark.sql.repl.eagerEval.enabled', True) \
.getOrCreate()

"""## Q1"""

import numpy as np
import matplotlib.pyplot as plt
import time

features = np.loadtxt('/content/drive/MyDrive/CSE 547 data/features.txt', delimiter = ',')
target = np.loadtxt('/content/drive/MyDrive/CSE 547 data/target.txt', delimiter = ',')

def cost(w, b, features, target, C = 100):
  loss = 0.5 * w @ w + C * np.sum(np.maximum(0, 1 - target * (w @ features.T + b)))
  return loss

"""Batch Gradient Descent"""

# initialize
w = np.zeros(features.shape[1])
b = 0
C = 100

eta = 3*1e-7
eps = 0.25

BGD_cost = []
BGD_iterations = 0

percent_cost = float("inf")
start_time = time.time()

while percent_cost >= eps:
  
  BGD_cost.append(cost(w, b, features, target, C))
  y_xw_b = target * (features @ w + b)
  selection = y_xw_b >= 1

  dLdw = -target[:, None] * features
  dLdb = -target
  dLdw[selection] = 0
  dLdb[selection] = 0
  dw = w + C * np.sum(dLdw, axis=0)
  db = C * np.sum(dLdb)

  w -= eta * dw
  b -= eta * db

  BGD_iterations += 1
  percent_cost = np.abs(BGD_cost[-1] - cost(w, b, features, target, C)) / BGD_cost[-1]* 100

  if percent_cost < eps:
    end_time = time.time()
    BGD_cost.append(cost(w, b, features, target, C))

print("Batch Gradient Descent takes {} seconds".format(end_time - start_time))

BGD_cost

"""Stochastic Gradient Descent"""

# initialize
w = np.zeros(features.shape[1])
b = 0
C = 100

eta = 0.0001
eps = 0.001

delta_cost = 0

# shuffle
reordered_index = list(range(features.shape[0]))
np.random.seed(0)
np.random.shuffle(reordered_index)
SGD_features = features[reordered_index]
SGD_target = target[reordered_index]
    
SGD_cost = [cost(w = w, b = b, features = SGD_features, target = SGD_target, C = C)]
SGD_iterations = 0

i = 0

start_time = time.time()

while True:
    
    SGD_feature_1 = SGD_features[i]
    SGD_target_1 = SGD_target[i]

    selection = SGD_target_1 * (SGD_feature_1 @ w + b) >= 1
    dLdw = 0 if selection else -SGD_target_1 * SGD_feature_1
    dLdb = 0 if selection else -SGD_target_1
    dw = w + C * dLdw
    db = C * dLdb
    w -= eta * dw
    b -= eta * db

    i += 1
    if i == features.shape[0]:
        i = 0
        np.random.shuffle(reordered_index)

    SGD_cost.append(cost(w = w, b = b, features = SGD_features, target = SGD_target, C = C))
    
    percent_delta = 100 * np.abs(SGD_cost[-2] - SGD_cost[-1]) / SGD_cost[-2]
    delta_cost = 0.5 * delta_cost + 0.5 * percent_delta

    SGD_iterations += 1

    if delta_cost < eps:
      end_time = time.time()
      break

print("Stochastic Gradient Descent takes {} seconds".format(end_time - start_time))

"""Mini Batch"""

# initialize
w = np.zeros(features.shape[1])
b = 0
C = 100

eta = 1e-5
eps = 0.01
beta = 20

delta_cost = 0

# shuffle
reordered_index = list(range(features.shape[0]))
np.random.seed(0)
np.random.shuffle(reordered_index)
MGD_features = features[reordered_index]
MGD_target = target[reordered_index]
    
MGD_cost = [cost(w = w, b = b, features = MGD_features, target = MGD_target, C = C)]
MGD_iterations = 0

l = 0

start_time = time.time()

while True:
    MGD_feature_1 = MGD_features[l:l + beta]
    MGD_target_1 = MGD_target[l:l + beta]

    selection = MGD_target_1 * (MGD_feature_1 @ w + b) >= 1
    dLdw = -MGD_target_1[:, None] * MGD_feature_1
    dLdb = -MGD_target_1
    dLdw[selection] = 0
    dLdb[selection] = 0
    dw = w + C * np.sum(dLdw, axis=0)
    db = C * np.sum(dLdb)

    w -= eta * dw
    b -= eta * db

    l += beta
    if l >= features.shape[0]:
        l = 0
        np.random.shuffle(reordered_index)
        MGD_features = features[reordered_index]
        MGD_target = target[reordered_index]
    
    MGD_cost.append(cost(w = w, b = b, features = MGD_features, target = MGD_target, C = C))
    percent_delta = 100 * np.abs(MGD_cost[-2] - MGD_cost[-1]) / MGD_cost[-2]
    delta_cost = 0.5 * delta_cost + 0.5 * percent_delta

    MGD_iterations += 1

    if delta_cost < eps:
        end_time = time.time()
        break
print("Stochastic Gradient Descent takes {} seconds".format(end_time - start_time))

len(MGD_cost)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

plt.figure()
plt.plot(np.arange(BGD_iterations + 1), BGD_cost, label = 'BGD')
plt.plot(np.arange(SGD_iterations + 1), SGD_cost, label = 'SGD')
plt.plot(np.arange(MGD_iterations + 1), MGD_cost, label = 'MGD')
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.title('Cost for Different Gradient Descent Methods')
plt.legend()



"""##Q2"""

q2data = open("/content/drive/MyDrive/browsing.txt", "r")







