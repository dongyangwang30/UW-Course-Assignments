---
title: "Stat 571 HW3"
author: "Dongyang Wang"
date: "2023-02-10"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list=ls())
set.seed(42)
```

## Question 1

### Question 1.1

```{r}
sixcity <- read.table("sixcity.dat", header = F)
colnames(sixcity) = c("wheezing", "id", "age", "smoking")
logistic_mod <- glm(wheezing~age*smoking, family = binomial(link = "logit"), 
                    data = sixcity)
results_logistic <- summary(logistic_mod)$coefficients[,c(1,2)]
results_logistic
```

The above shows the result including the coefficients and the standard errors for the naive logistic model.

### Question 1.2

```{r}
library(geepack)
gee_indep <- geeglm(wheezing ~ age * smoking,
        id = id, corstr = "independence",
        family= binomial, data = sixcity)
```

```{r}
library(gee)
gee_exch <- gee(wheezing ~ age * smoking,
        id = id, corstr = "exchangeable",
        family= binomial, data = sixcity)
```

```{r}
results_indep <- summary(gee_indep)$coefficients[,c(1,2)]
results_exch <- summary(gee_exch)$coefficients[,c(1,2)]
```

```{r}
library(kableExtra)
kbl(cbind(results_logistic,results_indep, results_exch),
  caption = "Estimates and Standar Errors Comparison 
  between GEE1 and logistic Regression")  %>%
  add_header_above(c(" " = 1, "logistic regression"=2, 
                     "Independence GEE1" = 2, "Exchangeable GEE1" = 2))%>%
  kableExtra::kable_styling(position = "center")

```

Based on the results above, the estimates for the coefficients are pretty similar across the methods. The standard errors tend to be larger in GEE methods for intercept and smoking, smaller for other variables. The results from independence and exchangeable structures are very similar in estimates and SEs.

In terms of interpretation, one unit increase in age is associated with about 0.14 decrease in the log odds of wheezing; smoking mothers are associated with 0.31 increase in log odds of wheezing compared with nonsmoker mothers; for smoking mothers the age is additionally 0.07 associated with the log odds of wheezing.

### Question 1.4

One potential way to to use age only at the baseline but also include the length of time people have participated in the study. That means, separating the current age variable into two separate varibles and model on them in the new model. For the interaction term we may use the length of time as one component. In this way, time can be modeled as a random effect.

## Question 2

### Question 2.1

```{r}
library(bindata)

p = 0.25
m = 300
n = 3
beta = c(-1.5, 0.5, 0.5) 
nrep = 200
```

```{r, warning = F, message = F}
library(geepack)
res = do.call(rbind, lapply(c(1:nrep), function(nrep){
  # matrices
  male = matrix(c(1,1,1, 0,0,0, 0,1,2), byrow = F, nrow = 3)
  female = matrix(c(1,1,1, 1,1,1, 0,1,2), byrow = F, nrow = 3)
  cor = matrix(p, ncol = n, nrow = n) + diag(1-p, n)
  
  # model
  logit_male = exp(male%*%beta)
  margin_prob_male = logit_male/(1 + logit_male)
  logit_female = exp(female%*%beta)
  margin_prob_female = logit_female/(1 + logit_female)
  
  # random data
  y_male = rmvbin(n = m/2, margprob = margin_prob_male, bincorr = cor)
  y_female = rmvbin(n = m/2, margprob = margin_prob_female, bincorr = cor)
  
  df = data.frame(id = rep(1:m, each = n),
                   female = rep(c(0,1), each = m*n/2),
                   time = rep(c(0,1,2), m),
                   y = c(t(rbind(y_male, y_female))))
  
  # model
  gee <- geeglm(y ~ female + time, family = binomial("logit"), id = id, 
                data = df, corstr ="exchangeable")
  
  # result
  data.frame(
    Estimate_intercept = summary(gee)$coefficients[1,1],
    Estimate_female = summary(gee)$coefficients[2,1],
    Estimate_time = summary(gee)$coefficients[3,1],
    SE_intercept = summary(gee)$coefficients[1,2],
    SE_female = summary(gee)$coefficients[2,2],
    SE_time = summary(gee)$coefficients[3,2],
    corr = summary(gee)$corr[1,1]
    )
  
}))
```

### Question 2.2

```{r}
res_2_pred = colMeans(res[,c(1:3,7)])
res_2_true = c(beta, p)
res_2_bias = res_2_pred - res_2_true
table_q2 <- rbind(res_2_pred, res_2_true, res_2_bias)
rownames(table_q2) = c("prediction", "true values", "bias")
colnames(table_q2) = c("intercept", "female", "time", "correlation")
kbl(table_q2,
  caption = "True, Predicted, and Bias for Key Variables")  %>%
  kableExtra::kable_styling(position = "center")
```

### Question 2.3

```{r}
res_3_pred = colMeans(res[,4:6])
res_3_empirical = apply(res[,1:3], 2, sd)
table_q3 <- rbind(res_3_pred, res_3_empirical)
rownames(table_q3) = c("prediction", "empirical")
colnames(table_q3) = c("intercept", "female", "time")
kbl(table_q3,
  caption = "Comparison of SEs")  %>%
  kableExtra::kable_styling(position = "center")
```

### Question 2.4

```{r}
p = 0.75
try({
  # matrices
  male = matrix(c(1,1,1, 0,0,0, 0,1,2), byrow = F, nrow = 3)
  female = matrix(c(1,1,1, 1,1,1, 0,1,2), byrow = F, nrow = 3)
  cor = matrix(p, ncol = n, nrow = n) + diag(1-p, n)
  
  # model
  logit_male = exp(male%*%beta)
  margin_prob_male = logit_male/(1 + logit_male)
  logit_female = exp(female%*%beta)
  margin_prob_female = logit_female/(1 + logit_female)
  
  # random data
  y_male = rmvbin(n = m/2, margprob = margin_prob_male, bincorr = cor)
  y_female = rmvbin(n = m/2, margprob = margin_prob_female, bincorr = cor)
  })
```

No, the correlation is too high to model. There is an error message detailing this "Error in commonprob2sigma(commonprob, simulvals) : Matrix commonprob not admissible".

## Question 3

### Question 3.1

```{r}
df = read.table("framingham.dat", header=F)
colnames(df) = c("age", "gender", "BMI_base", "BMI_10yrs", "cigarette_base", "cholst_base",
                 "cholst_2", "cholst_4", "cholst_6", "cholst_8", "cholst_10", "dead")
df$id <- seq.int(nrow(df))
df[df == -9] = NA
summary(df)
```

```{r}
library(data.table)
library(dplyr)
long_df <- melt(setDT(df), id.vars = c("age", "gender", "BMI_base", "BMI_10yrs", 
                                    "cigarette_base", "cholst_base", "dead", 
                                    "id"), variable.name = "year")
long_df$year = case_when(
  long_df$year == "cholst_2" ~ 2,
  long_df$year == "cholst_4" ~ 4,
  long_df$year == "cholst_6" ~ 6,
  long_df$year == "cholst_8" ~ 8,
  long_df$year == "cholst_10" ~ 10)

long_df$age_current = long_df$year + long_df$age
```

```{r}
df_subset = na.omit(long_df)
library(lme4)
lmm_q3 = lmer(value~ age+age_current+gender+gender*age_current + BMI_base 
           +(1+age_current|id), data = df_subset, REML = T)
summary(lmm_q3)
```

```{r}
library(geepack)
gee_q3 = geeglm(value~ age+age_current+gender+gender*age_current + BMI_base, id = id, data = df_subset, corstr = "exchangeable")
summary(gee_q3)
```

```{r}
results_q3a_1 <- summary(lmm_q3)$coefficients[,c(1,2)]
results_q3a_2 <- summary(gee_q3)$coefficients[,c(1,2)]
```

```{r}
kbl(cbind(round(results_q3a_1,4),round(results_q3a_2,4)),
  caption = "Parameter Estimate and Standar Error Comparison") %>%
  add_header_above(c(" "=1, "LMM"=2, "GEE1"=2)) %>%
  kableExtra::kable_styling(position = "center")
```

Per the comparisons, the results are generally similar in trend, including the intercept, age, gender, BMI, and the interaction term. The standard errors are similar yet different by some amounts. The only discrepancy lies in the age_current variable, which indicates how long the person has been in the study. Two models show similar standard errors but the estimates are different in sign.

## Question 3.2

The data generating process is similar to HW2. I recycled some of the code. To reiterate the logic: Under the random intercept model, since $var(Y) = 1 = \theta + \sigma^2$ and $corr(Y_{ij}, Y_{ik}) = \rho = \frac{\theta}{\theta + \sigma^2}$, we solve the equations and get $\theta = \rho$ and $\sigma^2 = 1 - \rho$. In this way, we can generate the x, e, b seperately and use a linear relationship we choose to generate the y values, without the need to sample y directly but achieving the same results.

```{r}
library(lme4)

# Set beta to 0.5 and 1
beta1 = 0.5
beta0 = 1
p = 0.5

params <- expand.grid(
  m = c(5,10,20, 50,100), # individuals
  n = c(5,10,20) # observations per individual
)

# For testing
#m = 10
#n = 5

gen.one <- function(m,n){
  
  total = m*n
  
  # Generate the variables
  x = rnorm(total, 0, 1)
  b = rep(rnorm(m, mean = 0, sd = sqrt(p)),n)
  e = rnorm(total, mean = 0, sd = sqrt(1-p))
  y = beta0 + beta1*x + b + e
  
  # LMM
  lmm = lmer(y ~ x + (1|b), REML = T)
  gee = geeglm(y~ x, id = b, corstr = "exchangeable")
  ols = lm(y ~ x + b)
  
  # Estimate variance for efficiency
  lmm_var0 = vcov(lmm)[1,1]
  lmm_var1 = vcov(lmm)[2,2]
  gee_var0 = vcov(gee)[1,1]
  gee_var1 = vcov(gee)[2,2]
  ols_var0 = vcov(ols)[1,1]
  ols_var1 = vcov(ols)[2,2]
  
  # Estimate coefficients
  lmm_coef0 = fixef(lmm)[1]
  lmm_coef1 = fixef(lmm)[2]
  gee_coef0 = coef(gee)[1]
  gee_coef1 = coef(gee)[2]
  ols_coef0 = coef(ols)[1]
  ols_coef1 = coef(ols)[2]
  
  # Estimate bias
  lmm_bias0 = lmm_coef0 - beta0
  lmm_bias1 = lmm_coef1 - beta1
  gee_bias0 = gee_coef0 - beta0
  gee_bias1 = gee_coef1 - beta1
  ols_bias0 = ols_coef0 - beta0
  ols_bias1 = ols_coef1 - beta1
  
  # lmm_coef0 = lmm_coef0, lmm_coef1 = lmm_coef1,
  # gee_coef0 = gee_coef0, gee_coef1 = gee_coef1,
  # ols_coef0 = ols_coef0, ols_coef1 = ols_coef1,
  return(data.frame(m = m, n = n,
                    lmm_var0 = lmm_var0, lmm_var1 = lmm_var1, 
                    gee_var0 = gee_var0, gee_var1 = gee_var1,
                    ols_var0 = ols_var0, ols_var1 = ols_var1,
                    lmm_bias0 = lmm_bias0, lmm_bias1 = lmm_bias1,
                    gee_bias0 = gee_bias0, gee_bias1 = gee_bias1,
                    ols_bias0 = ols_bias0, ols_bias1 = ols_bias1
                    ) )
}

```

```{r, message = F}
nrep = 1000

simulation <- do.call(rbind, lapply(c(1:nrow(params)), function(i){
  m <- params$m[i]
  n <- params$n[i]
  res <- do.call(rbind, lapply(c(1:nrep), function(nrep){
  gen.one(m,n)
  }))
  mean_res <- colMeans(res)
}))

simulation_res = as.data.frame(simulation)
```

```{r}
simulation_res_reshaped = reshape(simulation_res, direction="long", 
        varying=list(c("lmm_var0","gee_var0", "ols_var0"), 
                     c("lmm_var1","gee_var1", "ols_var1"),
                     c("lmm_bias0","gee_bias0", "ols_bias0"), 
                     c("lmm_bias1","gee_bias1", "ols_bias1")), 
        v.names=c("var0","var1","bias0", "bias1"))
```

```{r}
simulation_res_reshaped$method = case_when(
  simulation_res_reshaped$time == 1 ~ "LMM",
  simulation_res_reshaped$time == 2 ~ "GEE",
  simulation_res_reshaped$time == 3 ~ "OLS")
```

```{r}
library(ggplot2)
ggplot(data=simulation_res_reshaped, aes(x=m, y=abs(bias0), color = method))+geom_line()+
  facet_grid(cols=vars(n))

ggplot(data=simulation_res_reshaped, aes(x=m, y=abs(bias1), color = method))+geom_line()+
  facet_grid(cols=vars(n))

ggplot(data=simulation_res_reshaped, aes(x=m, y=sqrt(var0), color = method))+geom_line()+
  facet_grid(cols=vars(n))

ggplot(data=simulation_res_reshaped, aes(x=m, y=sqrt(var1), color = method))+geom_line()+
  facet_grid(cols=vars(n))
```

From the visualizations,  we can compare the results of the three models, using different sizes of m and n. We have generated 1000 replicates of the simulation, and the estimates are simply an average of the 1000 models obtained through simulations.

The LMM successfully takes into account the random and fixed effects. Regardless of the covariance structure, we can obtain identical results, compared with GEE's. It however, requires that the specification of the fixed and random effects to be correct to be able to calculate the correct results.

The GEE, on the other hand, provides a very flexible approach because it can specify various variance structures. For simplicity, I have only used the exchangeable structure for this HW. The drawback is probably that when the variance structure is misspecified, results can be off a lot.

OLS has the advantage being easy to implement and easy to understand, although it does not offer flexible interpretations especially for the random effects, since it has treated it as a fixed effect.

Across the methods, from my simulation results, the ols has the lowest variance for both beta parameters. The biases, however, show more diverse results for different methods. But the trend is generally that as sample size increases, all the methods show improvement in bias and variance.

## Question 4

To propose a marginal or population average model, I start by setting their means. To be simple, $Y_{i1}$ can follow normal distribution and $Y_{i2}$ can follow Bernoulli distribution. $\mu_{i1} = X_i^T \beta_1$ and  $\mu_{i2} = probit(X_i^T \beta_2)$. I can further specify the variances to be $var_1 = \sigma^2$ say 1, and $var_2 = probit(X_i^T \beta_2)(1 - probit(X_i^T \beta_2))$ per the Bernoulli distribution.

We can then specify the correlation between $Y_{i1}$ and $Y_{i2}$ to be $\rho$, then we would have the correlation matrix between the two. Then we would be able to easily model using GEE. $\sum_{i=1}^m D_i^T V_i^{-1} (Y_i - \mu_i) = 0$. Everything will be easy just like a usual GEE.


